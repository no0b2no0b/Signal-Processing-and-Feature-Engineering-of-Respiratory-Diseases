{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viaXsJ_VaQHa",
        "outputId": "4db4a6f7-6c2d-43ae-8fab-282a3e886b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndP3To0UZLkd",
        "outputId": "396bd4f0-3fad-4b8c-c41c-30d7ab3ea19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (67.7.2)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh8NCNgGew9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422b7cb1-144c-4f5f-9279-4a8a6029b9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Load various imports\n",
        "from datetime import datetime\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mypath = \"/content/gdrive/MyDrive/Major_Project/ICBHI_final_database/audio_and_txt_files/\"\n",
        "filenames = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith('.wav'))]"
      ],
      "metadata": {
        "id": "USyivqWqjCnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_id_in_file = [] # patient IDs corresponding to each file\n",
        "for name in filenames:\n",
        "    p_id_in_file.append(int(name[:3]))\n",
        "\n",
        "p_id_in_file = np.array(p_id_in_file)"
      ],
      "metadata": {
        "id": "SqQdaRkZjFND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pad_len = 862 # to make the length of all MFCC equal\n",
        "\n",
        "def extract_features(file_name):\n",
        "    \"\"\"\n",
        "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
        "    of the audio\"\"\"\n",
        "\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, duration=20)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None\n",
        "\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "XB8fWqU0jHv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [join(mypath, f) for f in filenames] # full paths of files\n",
        "p_diag = pd.read_csv(\"/content/gdrive/MyDrive/Major_Project/ICBHI_final_database/patient_diagnosis.csv\") # patient diagnosis file\n",
        "labels = []\n",
        "for x in p_id_in_file:\n",
        "  labels.append(p_diag[p_diag['patient_Id']==x]['Disease'].values[0]) # labels for audio files\n",
        "label=[]\n",
        "for i in  labels:\n",
        "    if i != 'Bronchiectasis':\n",
        "        i=\"NO\"\n",
        "    label.append(i)"
      ],
      "metadata": {
        "id": "kjNxJm8YjKXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in labels:\n",
        "  if(i=='Bronchiectasis'):\n",
        "    count+=1\n",
        "print(count)\n",
        "labels=np.array(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9kJdvrSjVwv",
        "outputId": "9e4df131-4866-48f9-9cd0-7c24d7ea772e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "\n",
        "# Iterate through each sound file and extract the features\n",
        "for file_name in filepaths:\n",
        "    data = extract_features(file_name)\n",
        "    features.append(data)\n",
        "\n",
        "print('Finished feature extraction from ', len(features), ' files')\n",
        "features = np.array(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB97-k20ZbR7",
        "outputId": "79cb4e5a-834b-49fc-bbbb-a1cf2ac526d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished feature extraction from  920  files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features= np.array(features) # convert to numpy array\n",
        "\n",
        "# delete the very rare diseases\n",
        "features1 = np.delete(features, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)\n",
        "\n",
        "labels1 = np.delete(labels, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)\n",
        "\n",
        "# print class counts\n",
        "unique_elements, counts_elements = np.unique(labels, return_counts=True)\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHxt4lUjhDk",
        "outputId": "64acd1b0-9fcf-4d97-d56a-fb7b500c6425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Bronchiectasis' 'NO']\n",
            " ['16' '904']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot class counts\n",
        "y_pos = np.arange(len(unique_elements))\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, unique_elements)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Disease')\n",
        "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
        "plt.show()\n",
        "\n",
        "# One-hot encode labels\n",
        "le = LabelEncoder()\n",
        "i_labels = le.fit_transform(labels)\n",
        "oh_labels = to_categorical(i_labels)\n",
        "\n",
        "# add channel dimension for CNN\n",
        "features1 = np.reshape(features, (*features.shape,1))\n",
        "\n",
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features1, oh_labels, stratify=oh_labels,\n",
        "                                                    test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "XUlRxbrDjldV",
        "outputId": "e1711532-697a-4c6a-803d-8ce9b1b0256d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 40\n",
        "num_columns = 862\n",
        "num_channels = 1\n",
        "\n",
        "num_labels = oh_labels.shape[1]\n",
        "filter_size = 2\n",
        "\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=filter_size,\n",
        "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "vzxzg-BTjoGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# Display model architecture summary\n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEjqp1MpjrCR",
        "outputId": "57b831e7-9b5e-444d-dab7-82e87023928e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 39, 861, 16)       80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 19, 430, 16)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 19, 430, 16)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 18, 429, 32)       2080      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 9, 214, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 9, 214, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 213, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 106, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 106, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 105, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 52, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 52, 128)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 128)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,570\n",
            "Trainable params: 43,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "6/6 [==============================] - 2s 210ms/step - loss: 20.3486 - accuracy: 0.0163\n",
            "Pre-training accuracy: 1.6304%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "num_epochs = 250\n",
        "num_batch_size = 128\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='mymodel2_{epoch:02d}.h5',\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_accuracy` score has improved.\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        verbose=1)\n",
        "]\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DDbb5RKjtZj",
        "outputId": "629e7de5-9cce-4c9a-8116-4d4aa71926b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.9783\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98370, saving model to mymodel2_01.h5\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.7965 - accuracy: 0.9783 - val_loss: 0.1883 - val_accuracy: 0.9837\n",
            "Epoch 2/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.9198\n",
            "Epoch 2: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.4904 - accuracy: 0.9198 - val_loss: 0.0813 - val_accuracy: 0.9837\n",
            "Epoch 3/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.9823\n",
            "Epoch 3: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.4455 - accuracy: 0.9823 - val_loss: 0.1292 - val_accuracy: 0.9837\n",
            "Epoch 4/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.9823\n",
            "Epoch 4: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.4029 - accuracy: 0.9823 - val_loss: 0.0770 - val_accuracy: 0.9837\n",
            "Epoch 5/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9823\n",
            "Epoch 5: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.1948 - accuracy: 0.9823 - val_loss: 0.6245 - val_accuracy: 0.6630\n",
            "Epoch 6/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9688\n",
            "Epoch 6: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.1214 - accuracy: 0.9688 - val_loss: 0.2386 - val_accuracy: 0.9457\n",
            "Epoch 7/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9823\n",
            "Epoch 7: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.1205 - accuracy: 0.9823 - val_loss: 0.1776 - val_accuracy: 0.9728\n",
            "Epoch 8/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9823\n",
            "Epoch 8: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.1033 - accuracy: 0.9823 - val_loss: 0.4976 - val_accuracy: 0.7446\n",
            "Epoch 9/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9837\n",
            "Epoch 9: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0890 - accuracy: 0.9837 - val_loss: 0.2824 - val_accuracy: 0.9293\n",
            "Epoch 10/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9823\n",
            "Epoch 10: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0677 - accuracy: 0.9823 - val_loss: 0.3422 - val_accuracy: 0.8967\n",
            "Epoch 11/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9823\n",
            "Epoch 11: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0665 - accuracy: 0.9823 - val_loss: 0.2905 - val_accuracy: 0.9239\n",
            "Epoch 12/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9851\n",
            "Epoch 12: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0629 - accuracy: 0.9851 - val_loss: 0.2695 - val_accuracy: 0.9348\n",
            "Epoch 13/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9851\n",
            "Epoch 13: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0586 - accuracy: 0.9851 - val_loss: 0.2568 - val_accuracy: 0.9348\n",
            "Epoch 14/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9864\n",
            "Epoch 14: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0606 - accuracy: 0.9864 - val_loss: 0.2383 - val_accuracy: 0.9402\n",
            "Epoch 15/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9851\n",
            "Epoch 15: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.0614 - accuracy: 0.9851 - val_loss: 0.2216 - val_accuracy: 0.9348\n",
            "Epoch 16/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9837\n",
            "Epoch 16: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 15s 2s/step - loss: 0.0591 - accuracy: 0.9837 - val_loss: 0.1886 - val_accuracy: 0.9402\n",
            "Epoch 17/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9851\n",
            "Epoch 17: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0556 - accuracy: 0.9851 - val_loss: 0.1714 - val_accuracy: 0.9565\n",
            "Epoch 18/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9796\n",
            "Epoch 18: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0600 - accuracy: 0.9796 - val_loss: 0.1778 - val_accuracy: 0.9565\n",
            "Epoch 19/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9796\n",
            "Epoch 19: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0683 - accuracy: 0.9796 - val_loss: 0.1483 - val_accuracy: 0.9674\n",
            "Epoch 20/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9837\n",
            "Epoch 20: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0669 - accuracy: 0.9837 - val_loss: 0.1375 - val_accuracy: 0.9620\n",
            "Epoch 21/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9851\n",
            "Epoch 21: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0625 - accuracy: 0.9851 - val_loss: 0.1453 - val_accuracy: 0.9620\n",
            "Epoch 22/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9864\n",
            "Epoch 22: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0533 - accuracy: 0.9864 - val_loss: 0.1428 - val_accuracy: 0.9620\n",
            "Epoch 23/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9851\n",
            "Epoch 23: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0526 - accuracy: 0.9851 - val_loss: 0.1628 - val_accuracy: 0.9620\n",
            "Epoch 24/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9837\n",
            "Epoch 24: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0924 - val_accuracy: 0.9783\n",
            "Epoch 25/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9837\n",
            "Epoch 25: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0671 - accuracy: 0.9837 - val_loss: 0.1881 - val_accuracy: 0.9620\n",
            "Epoch 26/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9823\n",
            "Epoch 26: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.0871 - val_accuracy: 0.9783\n",
            "Epoch 27/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9851\n",
            "Epoch 27: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.0533 - accuracy: 0.9851 - val_loss: 0.1894 - val_accuracy: 0.9674\n",
            "Epoch 28/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9891\n",
            "Epoch 28: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0437 - accuracy: 0.9891 - val_loss: 0.0987 - val_accuracy: 0.9674\n",
            "Epoch 29/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9851\n",
            "Epoch 29: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 15s 2s/step - loss: 0.0501 - accuracy: 0.9851 - val_loss: 0.1553 - val_accuracy: 0.9674\n",
            "Epoch 30/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9864\n",
            "Epoch 30: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0491 - accuracy: 0.9864 - val_loss: 0.1015 - val_accuracy: 0.9674\n",
            "Epoch 31/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9837\n",
            "Epoch 31: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0595 - accuracy: 0.9837 - val_loss: 0.1131 - val_accuracy: 0.9674\n",
            "Epoch 32/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9823\n",
            "Epoch 32: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0726 - accuracy: 0.9823 - val_loss: 0.1198 - val_accuracy: 0.9674\n",
            "Epoch 33/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9878\n",
            "Epoch 33: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0478 - accuracy: 0.9878 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
            "Epoch 34/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9851\n",
            "Epoch 34: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.1056 - val_accuracy: 0.9674\n",
            "Epoch 35/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9891\n",
            "Epoch 35: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 0.0962 - val_accuracy: 0.9674\n",
            "Epoch 36/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9851\n",
            "Epoch 36: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 15s 3s/step - loss: 0.0491 - accuracy: 0.9851 - val_loss: 0.1288 - val_accuracy: 0.9674\n",
            "Epoch 37/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9864\n",
            "Epoch 37: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0481 - accuracy: 0.9864 - val_loss: 0.0871 - val_accuracy: 0.9674\n",
            "Epoch 38/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9851\n",
            "Epoch 38: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.1010 - val_accuracy: 0.9674\n",
            "Epoch 39/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9878\n",
            "Epoch 39: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.1122 - val_accuracy: 0.9620\n",
            "Epoch 40/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9837\n",
            "Epoch 40: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0447 - accuracy: 0.9837 - val_loss: 0.0862 - val_accuracy: 0.9674\n",
            "Epoch 41/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9837\n",
            "Epoch 41: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 0.0948 - val_accuracy: 0.9674\n",
            "Epoch 42/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9864\n",
            "Epoch 42: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.0812 - val_accuracy: 0.9674\n",
            "Epoch 43/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9851\n",
            "Epoch 43: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.0865 - val_accuracy: 0.9674\n",
            "Epoch 44/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9851\n",
            "Epoch 44: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0384 - accuracy: 0.9851 - val_loss: 0.0936 - val_accuracy: 0.9728\n",
            "Epoch 45/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9905\n",
            "Epoch 45: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
            "Epoch 46/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9918\n",
            "Epoch 46: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0348 - accuracy: 0.9918 - val_loss: 0.0903 - val_accuracy: 0.9728\n",
            "Epoch 47/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9932\n",
            "Epoch 47: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0815 - val_accuracy: 0.9674\n",
            "Epoch 48/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9851\n",
            "Epoch 48: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.1306 - val_accuracy: 0.9728\n",
            "Epoch 49/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9878\n",
            "Epoch 49: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.0733 - val_accuracy: 0.9674\n",
            "Epoch 50/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9823\n",
            "Epoch 50: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0380 - accuracy: 0.9823 - val_loss: 0.0778 - val_accuracy: 0.9728\n",
            "Epoch 51/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9851\n",
            "Epoch 51: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0533 - accuracy: 0.9851 - val_loss: 0.0910 - val_accuracy: 0.9728\n",
            "Epoch 52/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9851\n",
            "Epoch 52: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0378 - accuracy: 0.9851 - val_loss: 0.0668 - val_accuracy: 0.9728\n",
            "Epoch 53/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9851\n",
            "Epoch 53: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0443 - accuracy: 0.9851 - val_loss: 0.1026 - val_accuracy: 0.9728\n",
            "Epoch 54/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9891\n",
            "Epoch 54: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.0768 - val_accuracy: 0.9674\n",
            "Epoch 55/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9905\n",
            "Epoch 55: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.1029 - val_accuracy: 0.9728\n",
            "Epoch 56/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9918\n",
            "Epoch 56: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 13s 2s/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.0803 - val_accuracy: 0.9674\n",
            "Epoch 57/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9918\n",
            "Epoch 57: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 0.0855 - val_accuracy: 0.9728\n",
            "Epoch 58/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9891\n",
            "Epoch 58: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 0.0744 - val_accuracy: 0.9674\n",
            "Epoch 59/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9864\n",
            "Epoch 59: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.0998 - val_accuracy: 0.9728\n",
            "Epoch 60/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9878\n",
            "Epoch 60: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.0718 - val_accuracy: 0.9674\n",
            "Epoch 61/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9918\n",
            "Epoch 61: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.0940 - val_accuracy: 0.9728\n",
            "Epoch 62/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9905\n",
            "Epoch 62: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.0708 - val_accuracy: 0.9674\n",
            "Epoch 63/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9891\n",
            "Epoch 63: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0282 - accuracy: 0.9891 - val_loss: 0.0845 - val_accuracy: 0.9783\n",
            "Epoch 64/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9918\n",
            "Epoch 64: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 15s 3s/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0713 - val_accuracy: 0.9674\n",
            "Epoch 65/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9946\n",
            "Epoch 65: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.0830 - val_accuracy: 0.9783\n",
            "Epoch 66/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9918\n",
            "Epoch 66: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0688 - val_accuracy: 0.9674\n",
            "Epoch 67/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9932\n",
            "Epoch 67: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0892 - val_accuracy: 0.9783\n",
            "Epoch 68/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9946\n",
            "Epoch 68: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.0685 - val_accuracy: 0.9674\n",
            "Epoch 69/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9932\n",
            "Epoch 69: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0763 - val_accuracy: 0.9728\n",
            "Epoch 70/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9932\n",
            "Epoch 70: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.0687 - val_accuracy: 0.9728\n",
            "Epoch 71/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9878\n",
            "Epoch 71: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0295 - accuracy: 0.9878 - val_loss: 0.0939 - val_accuracy: 0.9783\n",
            "Epoch 72/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9905\n",
            "Epoch 72: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0725 - val_accuracy: 0.9674\n",
            "Epoch 73/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9946\n",
            "Epoch 73: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.0901 - val_accuracy: 0.9783\n",
            "Epoch 74/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9918\n",
            "Epoch 74: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0685 - val_accuracy: 0.9728\n",
            "Epoch 75/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9946\n",
            "Epoch 75: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.0625 - val_accuracy: 0.9728\n",
            "Epoch 76/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9905\n",
            "Epoch 76: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0230 - accuracy: 0.9905 - val_loss: 0.0736 - val_accuracy: 0.9728\n",
            "Epoch 77/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9918\n",
            "Epoch 77: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
            "Epoch 78/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9891\n",
            "Epoch 78: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 0.0808 - val_accuracy: 0.9783\n",
            "Epoch 79/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9932\n",
            "Epoch 79: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
            "Epoch 80/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9918\n",
            "Epoch 80: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0842 - val_accuracy: 0.9783\n",
            "Epoch 81/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959\n",
            "Epoch 81: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0754 - val_accuracy: 0.9674\n",
            "Epoch 82/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9946\n",
            "Epoch 82: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0737 - val_accuracy: 0.9674\n",
            "Epoch 83/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959\n",
            "Epoch 83: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0867 - val_accuracy: 0.9837\n",
            "Epoch 84/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9959\n",
            "Epoch 84: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0739 - val_accuracy: 0.9674\n",
            "Epoch 85/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9973\n",
            "Epoch 85: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.0837 - val_accuracy: 0.9783\n",
            "Epoch 86/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9973\n",
            "Epoch 86: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0709 - val_accuracy: 0.9728\n",
            "Epoch 87/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9973\n",
            "Epoch 87: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.0752 - val_accuracy: 0.9728\n",
            "Epoch 88/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9959\n",
            "Epoch 88: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.0822 - val_accuracy: 0.9783\n",
            "Epoch 89/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9973\n",
            "Epoch 89: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0788 - val_accuracy: 0.9728\n",
            "Epoch 90/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9973\n",
            "Epoch 90: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
            "Epoch 91/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9946\n",
            "Epoch 91: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0717 - val_accuracy: 0.9783\n",
            "Epoch 92/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9932\n",
            "Epoch 92: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.0692 - val_accuracy: 0.9728\n",
            "Epoch 93/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9891\n",
            "Epoch 93: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0392 - accuracy: 0.9891 - val_loss: 0.0831 - val_accuracy: 0.9837\n",
            "Epoch 94/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9946\n",
            "Epoch 94: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0815 - val_accuracy: 0.9783\n",
            "Epoch 95/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9918\n",
            "Epoch 95: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.0765 - val_accuracy: 0.9783\n",
            "Epoch 96/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
            "Epoch 96: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 15s 2s/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0892 - val_accuracy: 0.9837\n",
            "Epoch 97/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9946\n",
            "Epoch 97: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0725 - val_accuracy: 0.9728\n",
            "Epoch 98/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9946\n",
            "Epoch 98: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0862 - val_accuracy: 0.9837\n",
            "Epoch 99/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9946\n",
            "Epoch 99: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0127 - accuracy: 0.9946 - val_loss: 0.0675 - val_accuracy: 0.9728\n",
            "Epoch 100/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9959\n",
            "Epoch 100: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0194 - accuracy: 0.9959 - val_loss: 0.0902 - val_accuracy: 0.9837\n",
            "Epoch 101/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9959\n",
            "Epoch 101: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0775 - val_accuracy: 0.9783\n",
            "Epoch 102/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
            "Epoch 102: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0896 - val_accuracy: 0.9783\n",
            "Epoch 103/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9946\n",
            "Epoch 103: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0828 - val_accuracy: 0.9783\n",
            "Epoch 104/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9959\n",
            "Epoch 104: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0907 - val_accuracy: 0.9783\n",
            "Epoch 105/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9973\n",
            "Epoch 105: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.0877 - val_accuracy: 0.9783\n",
            "Epoch 106/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9959\n",
            "Epoch 106: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0924 - val_accuracy: 0.9783\n",
            "Epoch 107/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9959\n",
            "Epoch 107: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0936 - val_accuracy: 0.9783\n",
            "Epoch 108/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9973\n",
            "Epoch 108: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0906 - val_accuracy: 0.9783\n",
            "Epoch 109/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9959\n",
            "Epoch 109: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0848 - val_accuracy: 0.9783\n",
            "Epoch 110/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9959\n",
            "Epoch 110: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0829 - val_accuracy: 0.9783\n",
            "Epoch 111/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9986\n",
            "Epoch 111: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0840 - val_accuracy: 0.9783\n",
            "Epoch 112/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9959\n",
            "Epoch 112: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0878 - val_accuracy: 0.9783\n",
            "Epoch 113/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9959\n",
            "Epoch 113: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9783\n",
            "Epoch 114/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9973\n",
            "Epoch 114: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0906 - val_accuracy: 0.9783\n",
            "Epoch 115/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9959\n",
            "Epoch 115: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0860 - val_accuracy: 0.9783\n",
            "Epoch 116/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9959\n",
            "Epoch 116: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0775 - val_accuracy: 0.9783\n",
            "Epoch 117/250\n",
            "5/6 [========================>.....] - ETA: 2s - loss: 0.0142 - accuracy: 0.9953\n",
            "Epoch 117: val_accuracy did not improve from 0.98370\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
            "Epoch 118/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9959\n",
            "Epoch 118: val_accuracy improved from 0.98370 to 0.98913, saving model to mymodel2_118.h5\n",
            "6/6 [==============================] - 15s 2s/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0917 - val_accuracy: 0.9891\n",
            "Epoch 119/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9973\n",
            "Epoch 119: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0939 - val_accuracy: 0.9783\n",
            "Epoch 120/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9973\n",
            "Epoch 120: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
            "Epoch 121/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
            "Epoch 121: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1037 - val_accuracy: 0.9783\n",
            "Epoch 122/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9973\n",
            "Epoch 122: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0930 - val_accuracy: 0.9783\n",
            "Epoch 123/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9973\n",
            "Epoch 123: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0939 - val_accuracy: 0.9837\n",
            "Epoch 124/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9973\n",
            "Epoch 124: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0902 - val_accuracy: 0.9783\n",
            "Epoch 125/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9986\n",
            "Epoch 125: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0920 - val_accuracy: 0.9783\n",
            "Epoch 126/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9973\n",
            "Epoch 126: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0862 - val_accuracy: 0.9783\n",
            "Epoch 127/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9986\n",
            "Epoch 127: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0880 - val_accuracy: 0.9837\n",
            "Epoch 128/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 128: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9783\n",
            "Epoch 129/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973\n",
            "Epoch 129: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0843 - val_accuracy: 0.9783\n",
            "Epoch 130/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9973\n",
            "Epoch 130: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0742 - val_accuracy: 0.9783\n",
            "Epoch 131/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9959\n",
            "Epoch 131: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0074 - accuracy: 0.9959 - val_loss: 0.0815 - val_accuracy: 0.9891\n",
            "Epoch 132/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9973\n",
            "Epoch 132: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0789 - val_accuracy: 0.9783\n",
            "Epoch 133/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9959\n",
            "Epoch 133: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0928 - val_accuracy: 0.9837\n",
            "Epoch 134/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973\n",
            "Epoch 134: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1053 - val_accuracy: 0.9837\n",
            "Epoch 135/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9986\n",
            "Epoch 135: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.1008 - val_accuracy: 0.9783\n",
            "Epoch 136/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
            "Epoch 136: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1009 - val_accuracy: 0.9783\n",
            "Epoch 137/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9973\n",
            "Epoch 137: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0051 - accuracy: 0.9973 - val_loss: 0.1011 - val_accuracy: 0.9783\n",
            "Epoch 138/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
            "Epoch 138: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
            "Epoch 139/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
            "Epoch 139: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
            "Epoch 140/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 140: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9783\n",
            "Epoch 141/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9973\n",
            "Epoch 141: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
            "Epoch 142/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
            "Epoch 142: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
            "Epoch 143/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
            "Epoch 143: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0901 - val_accuracy: 0.9837\n",
            "Epoch 144/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986\n",
            "Epoch 144: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0840 - val_accuracy: 0.9783\n",
            "Epoch 145/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 145: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0799 - val_accuracy: 0.9837\n",
            "Epoch 146/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9986\n",
            "Epoch 146: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0799 - val_accuracy: 0.9837\n",
            "Epoch 147/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9783\n",
            "Epoch 148/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9959\n",
            "Epoch 148: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0093 - accuracy: 0.9959 - val_loss: 0.0943 - val_accuracy: 0.9837\n",
            "Epoch 149/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9946\n",
            "Epoch 149: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0120 - accuracy: 0.9946 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
            "Epoch 150/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9946\n",
            "Epoch 150: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0121 - accuracy: 0.9946 - val_loss: 0.1320 - val_accuracy: 0.9837\n",
            "Epoch 151/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9959\n",
            "Epoch 151: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0576 - val_accuracy: 0.9783\n",
            "Epoch 152/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9918\n",
            "Epoch 152: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.0757 - val_accuracy: 0.9891\n",
            "Epoch 153/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9973\n",
            "Epoch 153: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0771 - val_accuracy: 0.9783\n",
            "Epoch 154/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9973\n",
            "Epoch 154: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0962 - val_accuracy: 0.9837\n",
            "Epoch 155/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9973\n",
            "Epoch 155: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1092 - val_accuracy: 0.9837\n",
            "Epoch 156/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 156: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1065 - val_accuracy: 0.9783\n",
            "Epoch 157/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9986\n",
            "Epoch 157: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
            "Epoch 158/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
            "Epoch 159/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9783\n",
            "Epoch 160/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9783\n",
            "Epoch 161/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9973\n",
            "Epoch 161: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0051 - accuracy: 0.9973 - val_loss: 0.0920 - val_accuracy: 0.9783\n",
            "Epoch 162/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9973\n",
            "Epoch 162: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.0926 - val_accuracy: 0.9837\n",
            "Epoch 163/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9986\n",
            "Epoch 163: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0974 - val_accuracy: 0.9837\n",
            "Epoch 164/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
            "Epoch 164: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0917 - val_accuracy: 0.9837\n",
            "Epoch 165/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9891\n",
            "Epoch 166/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 166: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 0.0812 - val_accuracy: 0.9837\n",
            "Epoch 167/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
            "Epoch 167: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0860 - val_accuracy: 0.9891\n",
            "Epoch 168/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 168: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0835 - val_accuracy: 0.9837\n",
            "Epoch 169/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 169: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 0.0840 - val_accuracy: 0.9837\n",
            "Epoch 170/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9891\n",
            "Epoch 171/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9959\n",
            "Epoch 171: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0078 - accuracy: 0.9959 - val_loss: 0.0841 - val_accuracy: 0.9837\n",
            "Epoch 172/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9986\n",
            "Epoch 172: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0864 - val_accuracy: 0.9891\n",
            "Epoch 173/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 173: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0754 - val_accuracy: 0.9837\n",
            "Epoch 174/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9891\n",
            "Epoch 175/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 175: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0659 - val_accuracy: 0.9837\n",
            "Epoch 176/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9986\n",
            "Epoch 176: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0025 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9891\n",
            "Epoch 177/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 177: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9891\n",
            "Epoch 178/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n",
            "Epoch 178: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.0753 - val_accuracy: 0.9783\n",
            "Epoch 179/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9891\n",
            "Epoch 180/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9783\n",
            "Epoch 181/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9973\n",
            "Epoch 181: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0044 - accuracy: 0.9973 - val_loss: 0.1137 - val_accuracy: 0.9891\n",
            "Epoch 182/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9837\n",
            "Epoch 183/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9986\n",
            "Epoch 183: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.1052 - val_accuracy: 0.9891\n",
            "Epoch 184/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9891\n",
            "Epoch 185/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9837\n",
            "Epoch 186/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9891\n",
            "Epoch 187/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9891\n",
            "Epoch 188/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n",
            "Epoch 188: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.1005 - val_accuracy: 0.9891\n",
            "Epoch 189/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 189: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1003 - val_accuracy: 0.9891\n",
            "Epoch 190/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
            "Epoch 190: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 16s 2s/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0981 - val_accuracy: 0.9837\n",
            "Epoch 191/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9891\n",
            "Epoch 192/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9973\n",
            "Epoch 192: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.1010 - val_accuracy: 0.9837\n",
            "Epoch 193/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9986\n",
            "Epoch 193: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.1060 - val_accuracy: 0.9837\n",
            "Epoch 194/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 194: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0991 - val_accuracy: 0.9891\n",
            "Epoch 195/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9837\n",
            "Epoch 196/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9973\n",
            "Epoch 196: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.1076 - val_accuracy: 0.9891\n",
            "Epoch 197/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9891\n",
            "Epoch 198/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9973\n",
            "Epoch 198: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 0.1023 - val_accuracy: 0.9891\n",
            "Epoch 199/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 199: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 0.1240 - val_accuracy: 0.9783\n",
            "Epoch 200/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9959\n",
            "Epoch 200: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0076 - accuracy: 0.9959 - val_loss: 0.1600 - val_accuracy: 0.9783\n",
            "Epoch 201/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.98913\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9891\n",
            "Epoch 202/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
            "Epoch 202: val_accuracy improved from 0.98913 to 0.99457, saving model to mymodel2_202.h5\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1400 - val_accuracy: 0.9946\n",
            "Epoch 203/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 203: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1533 - val_accuracy: 0.9891\n",
            "Epoch 204/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9891\n",
            "Epoch 205/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9973\n",
            "Epoch 205: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 0.1590 - val_accuracy: 0.9891\n",
            "Epoch 206/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9783\n",
            "Epoch 207/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9959\n",
            "Epoch 207: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0057 - accuracy: 0.9959 - val_loss: 0.0812 - val_accuracy: 0.9891\n",
            "Epoch 208/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9986\n",
            "Epoch 208: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
            "Epoch 209/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9959\n",
            "Epoch 209: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.1057 - val_accuracy: 0.9891\n",
            "Epoch 210/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9946\n",
            "Epoch 210: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0084 - accuracy: 0.9946 - val_loss: 0.0897 - val_accuracy: 0.9837\n",
            "Epoch 211/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9932\n",
            "Epoch 211: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0132 - accuracy: 0.9932 - val_loss: 0.2542 - val_accuracy: 0.9457\n",
            "Epoch 212/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9864\n",
            "Epoch 212: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.2409 - val_accuracy: 0.9837\n",
            "Epoch 213/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9864\n",
            "Epoch 213: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0641 - accuracy: 0.9864 - val_loss: 0.1386 - val_accuracy: 0.9783\n",
            "Epoch 214/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9891\n",
            "Epoch 214: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0523 - accuracy: 0.9891 - val_loss: 0.0643 - val_accuracy: 0.9891\n",
            "Epoch 215/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9946\n",
            "Epoch 215: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0105 - accuracy: 0.9946 - val_loss: 0.1677 - val_accuracy: 0.9837\n",
            "Epoch 216/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9932\n",
            "Epoch 216: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0131 - accuracy: 0.9932 - val_loss: 0.1550 - val_accuracy: 0.9891\n",
            "Epoch 217/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9946\n",
            "Epoch 217: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0275 - accuracy: 0.9946 - val_loss: 0.1641 - val_accuracy: 0.9837\n",
            "Epoch 218/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9973\n",
            "Epoch 218: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0763 - val_accuracy: 0.9837\n",
            "Epoch 219/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9837\n",
            "Epoch 220/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9973\n",
            "Epoch 220: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 0.0378 - val_accuracy: 0.9891\n",
            "Epoch 221/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9973\n",
            "Epoch 221: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0052 - accuracy: 0.9973 - val_loss: 0.0399 - val_accuracy: 0.9891\n",
            "Epoch 222/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9986\n",
            "Epoch 222: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 0.0406 - val_accuracy: 0.9891\n",
            "Epoch 223/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
            "Epoch 223: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0433 - val_accuracy: 0.9891\n",
            "Epoch 224/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9986\n",
            "Epoch 224: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0386 - val_accuracy: 0.9891\n",
            "Epoch 225/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9837\n",
            "Epoch 226/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9837\n",
            "Epoch 227/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9837\n",
            "Epoch 228/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9973\n",
            "Epoch 228: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0051 - accuracy: 0.9973 - val_loss: 0.0416 - val_accuracy: 0.9837\n",
            "Epoch 229/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9837\n",
            "Epoch 230/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9837\n",
            "Epoch 231/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9837\n",
            "Epoch 232/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 232: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 0.0410 - val_accuracy: 0.9837\n",
            "Epoch 233/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9837\n",
            "Epoch 234/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9986\n",
            "Epoch 234: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.0364 - val_accuracy: 0.9837\n",
            "Epoch 235/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9959\n",
            "Epoch 235: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0064 - accuracy: 0.9959 - val_loss: 0.0383 - val_accuracy: 0.9837\n",
            "Epoch 236/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n",
            "Epoch 236: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0369 - val_accuracy: 0.9946\n",
            "Epoch 237/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9973\n",
            "Epoch 237: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 0.0458 - val_accuracy: 0.9837\n",
            "Epoch 238/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9837\n",
            "Epoch 239/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9986\n",
            "Epoch 239: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 0.0396 - val_accuracy: 0.9837\n",
            "Epoch 240/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9837\n",
            "Epoch 241/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9837\n",
            "Epoch 242/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 15s 3s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9837\n",
            "Epoch 243/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9837\n",
            "Epoch 244/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9837\n",
            "Epoch 245/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9837\n",
            "Epoch 246/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n",
            "Epoch 246: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 15s 3s/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.0405 - val_accuracy: 0.9837\n",
            "Epoch 247/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9837\n",
            "Epoch 248/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9837\n",
            "Epoch 249/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9891\n",
            "Epoch 250/250\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9973\n",
            "Epoch 250: val_accuracy did not improve from 0.99457\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0032 - accuracy: 0.9973 - val_loss: 0.0460 - val_accuracy: 0.9837\n",
            "Training completed in time:  0:58:22.992997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b0kPNgOjwC_",
        "outputId": "ad2a12e0-a8e7-47c1-80a6-fcd9b3a88b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.01766304299235344\n",
            "Testing Accuracy:  0.016304347664117813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test) # label scores\n",
        "\n",
        "classpreds = np.argmax(preds, axis=1) # predicted classes\n",
        "\n",
        "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
        "\n",
        "n_classes=6 # number of classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_eGrPfVjyZl",
        "outputId": "3ce0183f-d822-4ed9-fbb2-6ea466906860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 126ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(2):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ],
      "metadata": {
        "id": "HHspMANYj1bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_names = [\"NO\", 'Bronchiectasis']\n",
        "\n",
        "# Plot ROC curves\n",
        "fig, ax = plt.subplots(figsize=(16, 10))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curve for Each Class')\n",
        "for i in range(2):\n",
        "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
        "ax.legend(loc=\"best\", fontsize='x-large')\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "XY4qN8cAj3kV",
        "outputId": "4400a00c-a512-4246-f6e3-69e09e9eb9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(y_testclass, classpreds, target_names=c_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6jY9nHmj87H",
        "outputId": "df8a4048-626d-4da2-d507-6bfbedf5d083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "            NO       0.50      0.67      0.57         3\n",
            "Bronchiectasis       0.99      0.99      0.99       181\n",
            "\n",
            "      accuracy                           0.98       184\n",
            "     macro avg       0.75      0.83      0.78       184\n",
            "  weighted avg       0.99      0.98      0.98       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(y_testclass, classpreds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KYDJlMUj_Lv",
        "outputId": "70151191-dd55-4d40-849b-5072e239958c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2   1]\n",
            " [  2 179]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "cm = confusion_matrix(y_testclass, classpreds)\n",
        "matrix_index = [\"Bronchiectasis\",\"No Bronchiectasis\"]\n",
        "df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "cm_perc = cm / cm_sum.astype(float) * 100\n",
        "annot = np.empty_like(cm).astype(str)\n",
        "nrows, ncols = cm.shape\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        c = cm[i, j]\n",
        "        p = cm_perc[i, j]\n",
        "        if i == j:\n",
        "            s = cm_sum[i]\n",
        "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "        elif c == 0:\n",
        "            annot[i, j] = ''\n",
        "        else:\n",
        "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "\n",
        "sn.heatmap(df_cm, annot=annot, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "Hl6bEhlMkBa1",
        "outputId": "6ac6860c-3282-4819-ae21-c79bf6780c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_QZExVIkDs9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}